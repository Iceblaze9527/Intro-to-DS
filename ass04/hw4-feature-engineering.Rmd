---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.4
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

## 0. Basic knowledge of feature engineering

```{python}
## Question 1: A good feature should be
```

**Answer1:**
representative and discriminative

```{python}
## Question 2: Why is image feature extraction hard? 
```

**Answer2:** 

background clutter, deformation, flipped picture, viewpoint variation, intra-class variation, scale variation, illumination conditions, occlusion, etc. 

```{python}
## Question 3: As we have learned in class, both 'Maximum entropy' and 'Smallest margin' can be used to
## measure uncertainty in active learning. Please explain which one is better for active learning and why?
## Note that: this is an open question and you can answer in Chinese as well.
```

In general, the maximum entropy approach performs better than smallest margin approach.

As can been seen from the algorithm, the smallest margin approach takes information only from two most uncertain sets of unlabeled data, while maximum entropy takes all subsets into consideration. Therefore, in binary-classification problems the two approaches will generate same results; while in multi-class cases, the maximum entropy approach will outperform smallest margin approach. This is the reason why maximum entropy is the most widely used algorithm in uncertainty sampling.

**Reference**: Ghasemi, Alireza & Rabiee, Hamid & Fadaee, Mohsen & Manzuri, M.T. & Rohban, Mohammad Hossein. (2016). Active Learning from Positive and Unlabeled Data. 


## 1. Text feature engineering

```{python}
## Given a corpus as:
corpus = ['The goal of this lecture is to explain text processing.',
          'The bag of words model is one such approach.',
          'Text processing via bag of words.',
          'Data science includes text processing']
```

```{python}
## Question 4: Use BOW to extract features of the given corpus. 
## Your code here
from sklearn.feature_extraction.text import CountVectorizer 
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)
print(X)
```

```{python}
## Question 5: Use TFIDF to extract features of the given corpus. 
## Your code here
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(corpus)
print(X)
```

```{python}
## Question 6: Use Word2Vec to extract features of the given corpus. 
from gensim.sklearn_api import W2VTransformer
## You should extract the vector representation of the word 'text' by the model trained on the given corpus.
## Note that: the formulation of the given corpus is different from that of common_texts, 
## you should transform the given corpus to the the formulation of common_texts first.

new_model =  W2VTransformer(size=10, min_count=1, seed=1)
common_words = []
splited_corp = [sentence[:-1].split() for sentence in corpus]
for lst in splited_corp:
    common_words.append(list(set(lst))) 

wordvecs = new_model.fit(common_words).transform(['text']) 
```

```{python}
common_words
```

```{python}
wordvecs
```

## 2. Time series feature engineering

```{python}
## Question 7: Use decompose (model='additive') to extract time series features of the given time series
from random import randrange
import math
from pandas import Series
series = Series([20*math.sin(i/18*math.pi) + i + randrange(10) for i in range(1,360)])
```

```{python}
from matplotlib import pyplot

from statsmodels.tsa.seasonal import seasonal_decompose
## 
## Your code here
## 
result = seasonal_decompose(series, model='additive', freq = 36)
result.plot()
```

#### Note:
from ``?seasonal_decompose`` we get:
```
freq : int, optional
    Frequency of the series. Must be used if x is not a pandas object.
    Overrides default periodicity of x if x is a pandas
    object with a timeseries index.
```
and according to [Julia on StackExchange](https://stats.stackexchange.com/questions/285718/seasonal-decomposition), the decomposition frequency is the ratio between the period of the observed phenomenon and your measurement(sampling) interval. In this example, the seasonal component of the series has period:

$$T = \frac{2\pi}{\pi/18} = 36$$

and the sampling interval is implied as 1, so our decomposition frequency is:

$$freq = 36/1 = 36$$

```{python}
## Question 8: Use Discrete Fourier Transform (DFT) to extract time series features of the given time series
import matplotlib.pyplot as plt
import numpy as np
series = Series([np.cos(2*math.pi*1/8*n+math.pi/8) for n in range(800)])
## 
## Your code here
## 
sp = np.fft.fft(series)
freq = np.fft.fftfreq(series.shape[-1])
plt.plot(freq, sp.real, freq, sp.imag)
plt.show()
```

## 3. Image feature engineering

```{python}
## Use SIFT in opencv-python to extract image features on the given image 'morning.jpg'
import cv2
import numpy as np
name = 'dog.jpg'
img = cv2.imread(name)
gray_img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
print("The shape of the image: ", gray_img.shape)
siftDetector= cv2.xfeatures2d.SIFT_create()
## Note that: SIFT was re-organized in opencv thus you should import it like this.
## finds the keypoint in the images
kp = siftDetector.detect(gray_img,None)
## draws the small circles on the locations of keypoints
cv2.drawKeypoints(gray_img,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
cv2.imwrite('sift_keypoint_' + name + '.jpg', img) ## Save Example
## directly find keypoints and descriptors in a single step 
kp, des = siftDetector.detectAndCompute(gray_img,None)
print("The shape of feature description: ", des.shape)
```

```{python}
## Question 9: Please rescale the given image 'dog.jpg' at a random ratio between 0.3 with 1.5.
## Note that: the width and height of the given image should be rescaled at a different ratio.
## Repeat this operation five times, then you will get five new images with different scale.
##
## Please extract the SIFT features of these images respectively and use 'imwrite' to save them.
## An example of saving keypoints on the input image is shown as follow:
## cv2.drawKeypoints(gray_img,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
## cv2.imwrite('sift_keypoint_' + name, img)

import random
name = 'dog.jpg'
img = cv2.imread(name)

siftDetector= cv2.xfeatures2d.SIFT_create()

for i in range(5):
    x_prop = random.uniform(0.3,1.5)
    y_prop = random.uniform(0.3,1.5)
    img_scaled = cv2.resize(img, (0,0), fx = x_prop, fy = y_prop) 
    gray_img_scaled = cv2.cvtColor(img_scaled, cv2.COLOR_BGR2GRAY)
    kp = siftDetector.detect(gray_img_scaled, None)
    cv2.drawKeypoints(gray_img_scaled,kp,img_scaled,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
    cv2.imwrite('sift_keypoint_scaled_' + name + str(i) + '.jpg', img_scaled)
```

```{python}
## Question 10: Please rotate the given image 'dog.jpg' 30, 60, 90, 120, 150, 180 degrees clockwise,
## then you will get six new images with different rotation angle.
## Please extract the SIFT features of these images respectively and use 'imwrite' to save them.
## An example of saving keypoints on the input image is shown as follow:
import numpy as np

name = 'dog.jpg'
img = cv2.imread(name)

siftDetector= cv2.xfeatures2d.SIFT_create()

for i in range(1,7):
    (height, width) = img.shape[:2] 
    
    img_canvas =  np.full((height + width, height + width, 3),(255,255,255), dtype = np.uint8)
    x_start = height//2 + 1
    x_end = height//2 + width
    y_start = width//2 + 1
    y_end = width//2 + height
    
    for j in range(y_start, y_end + 1):
        img_canvas[j][x_start:x_end + 1][:] = img[j-y_start][:][:]
    
    center = ((width+height)//2, (width+height)//2)
    
    rotate = cv2.getRotationMatrix2D(center, 30*i, scale = 1.0)
    img_rotated = cv2.warpAffine(img_canvas, rotate, (height + width, height + width), borderValue=(255, 255, 255)) 
    
    gray_img_rotated = cv2.cvtColor(img_rotated, cv2.COLOR_BGR2GRAY)
    kp = siftDetector.detect(gray_img_rotated, None)
    cv2.drawKeypoints(gray_img_rotated,kp,img_rotated,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
    cv2.imwrite('sift_keypoint_rotated_' + name + str(i)+ '.jpg', img_rotated)
```

```{python}

```
